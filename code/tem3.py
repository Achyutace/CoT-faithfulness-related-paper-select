import os
import time
import json
import requests
from typing import Optional

# === æ–°ç‰ˆ SDK å¼•å…¥æ–¹å¼ ===
from google import genai
from google.genai import types

# 1. é…ç½® API Key
os.environ["GOOGLE_API_KEY"] = "YOUR_GEMINI_API_KEY" # æ›¿æ¢ä½ çš„ Key
S2_API_KEY = None # å¦‚æœæœ‰ Semantic Scholar Key å¡«åœ¨è¿™é‡Œ

# 2. åˆå§‹åŒ–å®¢æˆ·ç«¯ (æ–°ç‰ˆç”¨æ³•)
client = genai.Client(api_key=os.environ["GOOGLE_API_KEY"])

# === è·¯å¾„ä¿®å¤ ===
try:
    # ç¡®ä¿è„šæœ¬ä½œä¸ºæ–‡ä»¶è¿è¡Œæ—¶èƒ½è·å–è·¯å¾„ï¼Œå¦‚æœæ˜¯äº¤äº’å¼ç¯å¢ƒ(jupyter)å¯èƒ½éœ€è¦ç¡¬ç¼–ç 
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    # print(BASE_DIR)
except NameError:
    BASE_DIR = os.getcwd()

DATA_PATH = os.path.join(BASE_DIR, "papers_data") # ç¤ºä¾‹ä¸‹è½½ç›®å½•

# ================= æ ¸å¿ƒé€»è¾‘ =================

def search_semantic_scholar(title: str) -> Optional[str]:
    """é€šè¿‡ Semantic Scholar è·å– PDF é“¾æ¥ (ä¿æŒä¸å˜)"""
    print(f"ğŸ” [S2] æœç´¢: {title}")
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    params = {"query": title, "limit": 1, "fields": "title,openAccessPdf"}
    headers = {"x-api-key": S2_API_KEY} if S2_API_KEY else {}

    try:
        resp = requests.get(base_url, params=params, headers=headers)
        if not resp.json().get("data"): return None
        
        paper = resp.json()["data"][0]
        pdf_info = paper.get("openAccessPdf")
        
        if pdf_info and pdf_info.get("url"):
            return pdf_info["url"]
        print("None")
        return None
    except Exception as e:
        print(f"âŒ æœç´¢å‡ºé”™: {e}")
        return None

def download_pdf(url: str, title: str) -> Optional[str]:
    """ä¸‹è½½ PDF"""
    if not os.path.exists(DATA_PATH):
        os.makedirs(DATA_PATH)
        print("already make dirs")
        
    safe_title = "".join([c for c in title if c.isalnum() or c in " ._-"]).strip()
    filename = f"{safe_title}.pdf"
    file_path = os.path.join(DATA_PATH, filename)

    if os.path.exists(file_path):
        return file_path

    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, stream=True, timeout=30)
        with open(file_path, "wb") as f:
            for chunk in resp.iter_content(chunk_size=8192):
                f.write(chunk)
        return file_path
    except Exception as e:
        print(f"âŒ ä¸‹è½½å‡ºé”™: {e}")
        return None

def analyze_paper_v2(file_path: str) -> str:
    """
    ä½¿ç”¨æ–°ç‰ˆ google-genai SDK è¿›è¡Œæ–‡ä»¶ä¸Šä¼ å’Œåˆ†æ
    """
    print(f"ğŸš€ [Gemini] æ­£åœ¨ä¸Šä¼ : {os.path.basename(file_path)}")
    
    # --- æ–°ç‰ˆä¸Šä¼ å†™æ³• ---
    # ä½¿ç”¨ client.files.upload
    with open(file_path, "rb") as f:
        file_ref = client.files.upload(file=f)
    
    # ç­‰å¾…å¤„ç† (æ–°ç‰ˆä¸å†éœ€è¦æ‰‹åŠ¨å†™ while å¾ªç¯æŸ¥è¯¢çŠ¶æ€ï¼ŒSDK å†…éƒ¨ä¼˜åŒ–äº†ï¼Œ
    # ä½†ä¸ºäº†ä¿é™©èµ·è§ï¼Œå¦‚æœæ–‡ä»¶å¾ˆå¤§ï¼Œå¯ä»¥ç”¨ client.files.get æ£€æŸ¥ state)
    while file_ref.state.name == "PROCESSING":
        time.sleep(1)
        file_ref = client.files.get(name=file_ref.name)
        
    if file_ref.state.name == "FAILED":
        raise ValueError("æ–‡ä»¶å¤„ç†å¤±è´¥")
        
    print("ğŸ§  AI æ­£åœ¨åˆ†æ...")

    prompt = """
    æ²¡é—®é¢˜ï¼Œä¸ºäº†è®©ä½ ä»¬é˜…è¯»å’Œæ•´ç†æ•ˆç‡æœ€å¤§åŒ–ï¼Œæˆ‘æŠŠè¾“å‡ºè¦æ±‚å…¨éƒ¨æ”¹ä¸ºä¸­æ–‡ï¼ŒåŒæ—¶ä¿ç•™å…³é”®æœ¯è¯­çš„è‹±æ–‡åŸè¯ï¼ˆæ–¹ä¾¿ä½ ä»¬å¼•ç”¨å’Œæ£€ç´¢ï¼‰ã€‚

è¯·ä½¿ç”¨ä¸‹é¢è¿™ç‰ˆ Promptï¼Œç›´æ¥å‘ç»™ AIï¼ˆClaude/GPT-4oï¼‰ï¼Œå®ƒä¼šå˜èº«ä¸ºä¸€ä¸ª**â€œä¸­æ–‡ç»¼è¿°é¢†è¯»å‘˜â€**ï¼š

ğŸ“‹ ä¸“ç”¨ Promptï¼šCoT Unfaithfulness ç—…ç†åˆ†æï¼ˆä¸­æ–‡ç‰ˆï¼‰
ã€è§’è‰²è®¾å®šã€‘ ä½ æ˜¯ä¸€ä½ä¸¥è‹›çš„ NLP ä¼šè®®å®¡ç¨¿äººï¼Œæ­£åœ¨ååŠ©æˆ‘æ’°å†™ä¸€ç¯‡å…³äº Chain-of-Thought (CoT) Faithfulnessï¼ˆæ€ç»´é“¾å¿ å®åº¦ï¼‰ çš„ç»¼è¿°è®ºæ–‡ã€‚ ä½ çš„ä»»åŠ¡æ˜¯æ·±å…¥åˆ†ææˆ‘ä¸Šä¼ çš„è®ºæ–‡ï¼Œä¸“é—¨æŒ–æ˜å…¶ä¸­æåˆ°çš„ â€œä¸å¿ å®ç°è±¡ (Unfaithful Phenomena)â€ï¼ˆå³æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ä¸çœŸå®å†³ç­–ä¸ä¸€è‡´ï¼Œæˆ–å­˜åœ¨æ¬ºéª—/ä¼ªé€ é€»è¾‘çš„æƒ…å†µï¼‰ã€‚

ã€é˜…è¯»æŒ‡ä»¤ã€‘

å¿½ç•¥å¹å˜˜ï¼š è·³è¿‡ Abstract å’Œ Introduction ä¸­ä½œè€…å¯¹è‡ªå·±æ¨¡å‹æ€§èƒ½çš„è‡ªå¤¸ã€‚

å¯»æ‰¾ç—›ç‚¹ï¼š é‡ç‚¹é˜…è¯» Motivation, Problem Definition, å’Œ Error Analysis éƒ¨åˆ†ã€‚

é€†å‘åˆ†æï¼š å¦‚æœè¿™æ˜¯ä¸€ç¯‡æå‡ºæ–°æ–¹æ³•çš„è®ºæ–‡ï¼Œè¯·è¯¦ç»†æè¿°å®ƒåˆ°åº•æ˜¯ä¸ºäº†è§£å†³ä»€ä¹ˆå…·ä½“çš„â€œä¸å¿ å®â€é—®é¢˜è€Œæå‡ºçš„ã€‚

ã€è¾“å‡ºæ ¼å¼ï¼ˆè¯·ä¸¥æ ¼ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼‰ã€‘

è¯·æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š

1. æ ¸å¿ƒä¸å¿ å®ç°è±¡ (The Phenomenon)
ç°è±¡åç§°ï¼š ç»™è¿™ä¸ªç°è±¡èµ·ä¸€ä¸ªç®€çŸ­çš„ä¸­æ–‡æ ‡ç­¾ï¼Œå¹¶é™„å¸¦è‹±æ–‡æœ¯è¯­ï¼ˆä¾‹å¦‚ï¼šäº‹ååˆç†åŒ– / Post-hoc Rationalizationï¼Œè°„åªš / Sycophancyï¼Œé€»è¾‘è·³è·ƒ / Logical Gapï¼‰ã€‚

æœºåˆ¶å®šä¹‰ï¼š ç”¨é€šä¿—çš„è¯­è¨€è§£é‡Šåœ¨è¿™é‡Œ CoT æ˜¯æ€ä¹ˆâ€œæ’’è°â€æˆ–â€œå¤±æ•ˆâ€çš„ï¼Ÿï¼ˆä¾‹å¦‚ï¼šâ€œæ¨¡å‹å…ˆæ ¹æ®åè§çŒœå‡ºäº†ç­”æ¡ˆï¼Œç„¶åç¼–é€ äº†ä¸€æ®µè™šå‡çš„æ¨ç†è¿‡ç¨‹æ¥å‡‘è¿™ä¸ªç­”æ¡ˆã€‚â€ï¼‰

ä¸¥é‡ç¨‹åº¦ï¼š è¿™æ˜¯è½»å¾®çš„é€»è¾‘é”™è¯¯ï¼Œè¿˜æ˜¯å®Œå…¨çš„æ¨ç†ä¸ç­”æ¡ˆè„±èŠ‚ï¼Ÿ

2. è§¦å‘åœºæ™¯ä¸é¢†åŸŸ (Context & Domain)
è§¦å‘æ¡ä»¶ï¼š åœ¨ä»€ä¹ˆæƒ…å†µä¸‹å®¹æ˜“å‡ºç°è¿™ç§ä¸å¿ å®ï¼Ÿï¼ˆä¾‹å¦‚ï¼šâ€œå½“ç”¨æˆ·è¾“å…¥å¸¦æœ‰è¯¯å¯¼æ€§æç¤ºæ—¶â€ã€â€œå½“é—®é¢˜æ¶‰åŠé•¿æ–‡æœ¬æ£€ç´¢æ—¶â€ã€â€œå½“ç­”æ¡ˆé€‰é¡¹åˆ†å¸ƒä¸å‡è¡¡æ—¶â€ï¼‰ã€‚

æ‰€å±é¢†åŸŸï¼š è®ºæ–‡ä¸»è¦åœ¨å“ªä¸ªé¢†åŸŸç ”ç©¶æ­¤é—®é¢˜ï¼Ÿï¼ˆæ•°å­¦ã€å¸¸è¯†æ¨ç†ã€åŒ»å­¦ã€ç¤¾ä¼šç§‘å­¦ã€ä»£ç ç­‰ï¼‰ã€‚

3. å…·ä½“è¡¨ç°/æ¡ˆä¾‹ (Manifestation)
æµç¨‹å¤ç°ï¼š è¯·æ ¹æ®è®ºæ–‡å†…å®¹ï¼Œæ„æƒ³æˆ–æ‘˜å½•ä¸€ä¸ªå…·ä½“çš„ Input -> CoT -> Output é”™è¯¯æ¡ˆä¾‹ã€‚

ç”¨æˆ·è¾“å…¥ï¼š ...

æ¨¡å‹å†…å¿ƒ/çœŸå®å€¾å‘ï¼ˆå¦‚æœ‰ï¼‰ï¼š ...

æ¨¡å‹ç”Ÿæˆçš„è™šå‡ CoTï¼š ...

éªŒè¯è¯æ®ï¼š ä½œè€…æ˜¯å¦‚ä½•è¯æ˜è¿™æ˜¯ä¸å¿ å®çš„ï¼Ÿï¼ˆä¾‹å¦‚ï¼šâ€œä½œè€…é€šè¿‡å¹²æ‰°è¾“å…¥å‘ç° CoT å˜äº†ä½†ç­”æ¡ˆæ²¡å˜â€ã€â€œä½œè€…ä½¿ç”¨äº†çº¿æ€§æ¢é’ˆå‘ç°ç­”æ¡ˆåœ¨ç¬¬ä¸€å±‚å°±ç¡®å®šäº†â€ï¼‰ã€‚

4. ç»¼è¿°å½’ç±»æ ‡ç­¾ (Taxonomy Tags)
è¯·åˆ¤æ–­è¿™ç¯‡è®ºæ–‡ä¸»è¦è§£å†³å“ªç±»é—®é¢˜ï¼ˆå¯å¤šé€‰ï¼Œæ‰“å‹¾ [x]ï¼‰ï¼š

[ ] é€»è¾‘æœ‰æ•ˆæ€§é—®é¢˜ (Validity/Spuriousness): è§£å†³â€œè¿‡ç¨‹ä¸å¯¹ä½†ç­”æ¡ˆè’™å¯¹äº†â€æˆ–â€œé€»è¾‘æ–­å±‚â€çš„é—®é¢˜ã€‚

[ ] è¯šå®æ€§ä¸å¯¹é½é—®é¢˜ (Honesty/Sycophancy): è§£å†³â€œè°„åªšç”¨æˆ·â€ã€â€œæ¬ºéª—â€ã€â€œäº‹ååˆç†åŒ–â€çš„é—®é¢˜ã€‚

[ ] é€æ˜åº¦ä¸å¯ç›‘æ§æ€§é—®é¢˜ (Transparency/Grounding): è§£å†³â€œé»‘ç›’éš¾æ‡‚â€ã€â€œå¼•ç”¨è™šå‡è¯æ®â€ã€â€œäººç±»æ— æ³•éªŒè¯â€çš„é—®é¢˜ã€‚

æ³¨æ„ï¼š è¯·ä¿æŒå®¢è§‚ã€æ‰¹åˆ¤çš„è¯­æ°”ã€‚å¦‚æœè®ºæ–‡åªæ˜¯å•çº¯åˆ·æ¦œè€Œæ²¡æœ‰æ·±å…¥åˆ†æ Faithfulness çš„æœºç†ï¼Œè¯·ç›´æ¥æŒ‡å‡ºâ€œæœ¬æ–‡ç¼ºä¹å¯¹ä¸å¿ å®æœºç†çš„æ·±å…¥åˆ†æâ€ã€‚
    """

    # --- æ–°ç‰ˆç”Ÿæˆå†™æ³• ---
    # 1. åªæœ‰ model, contents, config ä¸‰ä¸ªä¸»è¦å‚æ•°
    # 2. config ä½¿ç”¨ types.GenerateContentConfig å°è£…
    response = client.models.generate_content(
        model="gemini-1.5-pro",
        contents=[file_ref, prompt],
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            temperature=0.1
        )
    )
    
    return response.text

# ================= è¿è¡Œ =================
if __name__ == "__main__":
    target_title = "Attention Is All You Need"
    
    
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šå¯ä»¥æ”¾å…¥ä¸€ä¸ªåˆ—è¡¨å¾ªç¯å¤„ç†
    import os
    import pandas as pd
    DATA_PATH = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    print(DATA_PATH)
    
    df = pd.read_csv(f"{DATA_PATH}/DATA/sort_by_has_phenomenon/1faithfulness_papers_true_v1.csv")
    titles = df['title'].tolist()
    
    
    for title in titles:
        pdf_url = search_semantic_scholar(title)
        if pdf_url:
            local_path = download_pdf(pdf_url, title)
            if local_path:
                res = analyze_paper_v2(local_path)
                # ä¿å­˜ä¸ºå¯¹åº”æ ‡é¢˜.markdown
                with open(f"{DATA_PATH}/{title}.md", "w+", encoding="utf-8") as f:
                    f.write(res)